# Proyecto de Reconocimiento de Emociones Faciales en Tiempo Real ü§ñ

Este proyecto es una aplicaci√≥n desarrollada en Python que utiliza una Red Neuronal para detectar rostros en tiempo real a trav√©s de una c√°mara web y clasificar su expresi√≥n facial en una de siete emociones: **enojo, disgusto, miedo, felicidad, tristeza, sorpresa y neutral**.

El modelo de IA ha sido entrenado desde cero utilizando el dataset FER-2013 y aplicando t√©cnicas avanzadas para mejorar la precisi√≥n en emociones dif√≠ciles de distinguir.

## ‚ú® Caracter√≠sticas Principales

* **Detecci√≥n de Rostros en Tiempo Real:** Utiliza OpenCV para localizar rostros en el feed de la c√°mara.
* **Clasificaci√≥n de 7 Emociones:** Implementa un modelo de Keras/TensorFlow para identificar la expresi√≥n facial.
* **Modelo Optimizado:** Entrenado con t√©cnicas avanzadas para mejorar la precisi√≥n:
    * **Aumento de Datos (Data Augmentation):** Para crear m√°s ejemplos de entrenamiento.
    * **Ponderaci√≥n de Clases (Class Weights):** Para combatir el desbalance del dataset.
    * **Normalizaci√≥n por Lotes (Batch Normalization):** Para un entrenamiento m√°s r√°pido y estable.
    * **Tasa de Aprendizaje Adaptativa:** Para un ajuste fino del modelo.
* **Interfaz Visual Simple:** Muestra el resultado directamente en la ventana de video.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

* **Python 3.10+**
* **TensorFlow / Keras:** Para la construcci√≥n y entrenamiento de la red neuronal.
* **OpenCV:** Para la captura de video y detecci√≥n de rostros.
* **NumPy y Pandas:** Para la manipulaci√≥n de datos.
* **Scikit-learn:** Para el c√°lculo de la ponderaci√≥n de clases.
* **Dataset:** [FER-2013 de Kaggle](https://www.kaggle.com/datasets/msambare/fer2013)

## üìÅ Estructura del Proyecto

```
ROBOT-EMOCIONAL-LAB-VR/
‚îú‚îÄ‚îÄ venv/                     # Entorno virtual de Python
‚îú‚îÄ‚îÄ .gitignore                # Archivos ignorados por Git
‚îú‚îÄ‚îÄ modelo_emociones_final.keras # Modelo entrenado y listo para usar
‚îú‚îÄ‚îÄ fer2013.csv               # Dataset (debe descargarse por separado)
‚îú‚îÄ‚îÄ entrenar_modelo_final.py  # Script para entrenar el modelo (optimizado para Colab)
‚îú‚îÄ‚îÄ reconocimiento_en_vivo.py # Script principal para ejecutar la aplicaci√≥n
‚îî‚îÄ‚îÄ README.md                 # La documentaci√≥n del proyecto
```

## ‚öôÔ∏è Configuraci√≥n e Instalaci√≥n

Sigue estos pasos para poner en marcha el proyecto en tu m√°quina local.

**1. Clona el Repositorio**
```bash
git clone [git@github.com:monboga/robot-emocional-lab-vr.git](git@github.com:monboga/robot-emocional-lab-vr.git)
cd ROBOT-EMOCIONAL-LAB-VR
```

**2. Crea y Activa el Entorno Virtual**
```bash
# Crear el entorno
python -m venv venv

# Activar en Windows
venv\Scripts\activate.ps1

# Activar en Mac/Linux
source venv/bin/activate
```

**3. Instala las Dependencias**
Crea un archivo `requirements.txt` con el siguiente comando y luego instala las librer√≠as.
```bash
# Este comando crea el archivo (hazlo una sola vez)
pip freeze > requirements.txt

# Instala las librer√≠as desde el archivo
pip install -r requirements.txt
```

**4. Descarga los Archivos Necesarios**
* **Dataset:** Descarga el archivo `fer2013.csv` desde [este enlace de Kaggle](https://www.kaggle.com/datasets/msambare/fer2013) y col√≥calo en la ra√≠z del proyecto.
* **Modelo Pre-entrenado:** Aseg√∫rate de tener el archivo `modelo_emociones_final.keras` en la ra√≠z del proyecto.

## üöÄ Uso del Proyecto

### Detecci√≥n en Tiempo Real

Para ejecutar la aplicaci√≥n principal, simplemente corre el siguiente comando en tu terminal (con el entorno virtual activado):
```bash
python reconocimiento_en_vivo.py
```
Presiona la tecla **'q'** para cerrar la aplicaci√≥n.

### Re-entrenar el Modelo

El entrenamiento es un proceso que consume muchos recursos. Se recomienda encarecidamente realizarlo en **Google Colab** utilizando una GPU.
1.  Sube el archivo `entrenar_modelo_final.py` y el dataset `fer2013.csv` a tu Google Drive.
2.  Abre el script en un cuaderno de Colab.
3.  Activa el acelerador por hardware (GPU).
4.  Ejecuta el cuaderno para entrenar y guardar un nuevo archivo `.keras`.

## üß† Proceso de Entrenamiento del Modelo

El modelo es una **Red Neuronal** dise√±ada para la clasificaci√≥n de im√°genes. Para lograr una mayor precisi√≥n en emociones poco representadas en el dataset (como "miedo" o "enojo"), se implementaron las siguientes estrategias durante el entrenamiento:

* **Ponderaci√≥n de Clases:** Se asign√≥ un "peso" mayor a las clases con menos im√°genes para que el modelo les prestara m√°s atenci√≥n durante el aprendizaje.
* **Aumento de Datos:** Se generaron im√°genes sint√©ticas con variaciones (rotaci√≥n, zoom, etc.) para aumentar la diversidad del dataset.
* **Batch Normalization:** Se incluyeron capas de normalizaci√≥n para acelerar la convergencia y estabilizar el entrenamiento.
* **ReduceLROnPlateau:** Se utiliz√≥ un callback para ajustar din√°micamente la tasa de aprendizaje, permitiendo un ajuste m√°s fino en las etapas finales.

## üîÆ Mejoras Futuras

* **Usar un detector de rostros m√°s moderno** como MediaPipe para mayor velocidad y precisi√≥n.
* **Entrenar con un dataset de mayor calidad** como AffectNet o CK+ para mejorar a√∫n m√°s el reconocimiento de emociones sutiles.
* **Optimizar la inferencia con ONNX Runtime** para reducir el consumo de CPU (una vez que las dependencias de `tf2onnx` se estabilicen con las versiones m√°s recientes de TensorFlow).